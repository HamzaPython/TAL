{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bleu score:\n",
    "## Définition:\n",
    "BLEU (the Bilingual Evaluation Understudy), est un algorithme d'évaluation automatique d'une MT (machine traduction) qui a été proposé par Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu à 2002, cet algorithme compare une traduction candidate avec une traduction référence et calcule un score entre 0 et 1.\n",
    "\n",
    "## Approche théorique:\n",
    "\\begin{equation*}\n",
    "BLEU = BP\\prod_{k=1}^{n}{p_k}^{w_k}=e^{ln(BP)}e^{\\sum^{n}_{k=1}w_kln(p_k)}\n",
    "\\end{equation*}\n",
    "$\n",
    "Avec: BP = min(1, \\frac{hypothesis\\ lenght}{reference\\ lenght})\\quad et \\quad p_k = \\frac{correct\\ k-grams}{total\\ k-grams}\n",
    "$\n",
    "\n",
    "\n",
    "L'idée principale de BLEU est de comparer les n-grams d'une traduction candidate avec les n-grams d'une ou plusieurs traductions références et compter le nombre de sémelarité (calculer une précision pour chaque k-gram 0<k<n).\n",
    "cette méthode respecte les 2 aspects de traduction:\n",
    "- adequacy: Combien de la signification exprimée dans la traduction standard (référence) ou la source est également exprimée dans la traduction candidate. et donc une traduction candidate qui a les mêmes mots (1-grams) d'une traduction référence servi à respecter cette norme.\n",
    "- fluency: est-ce qu'une traduction candidate est grammaticalement bien informée ou non. ce qui peut être mesuré par les n-grams.\n",
    "\n",
    "L'algorithme BLEU prit en considération aussi qu'une traduction candidate ne doit pas être trop longue ni trop court par rapport au référence. donc:\n",
    "- si elle est trop longue que sa référence, le score calculé va être pénalisé par les n-grams.\n",
    "- si elle est trop court que sa référence, le score calculé va être pénalisé par un facteur multiplicative (BP).\n",
    "donc une bonne traduction doit avoir une longueur, un ordre des mots, un choix des mots proches de sa référence.\n",
    "\n",
    "## Approche pratique:\n",
    "\n",
    "Natural Language Toolkit library (NLTK) propose une implémentation de BLEU qu'on va utiliser dans notre projet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reference = [\"my name is hamza jamal\".split()]\n",
    "candidate = \"hamza jamal is a name of me\".split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Précision:\n",
    "#### Les n-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate n-grams:\n",
      "1-grams: [('hamza',), ('jamal',), ('is',), ('a',), ('name',), ('of',), ('me',)]\n",
      "2-grams: [('hamza', 'jamal'), ('jamal', 'is'), ('is', 'a'), ('a', 'name'), ('name', 'of'), ('of', 'me')]\n",
      "3-grams: [('hamza', 'jamal', 'is'), ('jamal', 'is', 'a'), ('is', 'a', 'name'), ('a', 'name', 'of'), ('name', 'of', 'me')]\n",
      "4-grams: [('hamza', 'jamal', 'is', 'a'), ('jamal', 'is', 'a', 'name'), ('is', 'a', 'name', 'of'), ('a', 'name', 'of', 'me')]\n",
      "\n",
      "reference n-grams:\n",
      "1-grams: [('my',), ('name',), ('is',), ('hamza',), ('jamal',)]\n",
      "2-grams: [('my', 'name'), ('name', 'is'), ('is', 'hamza'), ('hamza', 'jamal')]\n",
      "3-grams: [('my', 'name', 'is'), ('name', 'is', 'hamza'), ('is', 'hamza', 'jamal')]\n",
      "4-grams: [('my', 'name', 'is', 'hamza'), ('name', 'is', 'hamza', 'jamal')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "precisions = []\n",
    "print(\"candidate n-grams:\")\n",
    "for i in range(1,5):\n",
    "    cand_i_grams = list(ngrams(candidate, i))\n",
    "    print(\"{}-grams: {}\".format(i,cand_i_grams))\n",
    "print()\n",
    "print(\"reference n-grams:\")\n",
    "for i in range(1,5):\n",
    "    ref_i_grams = list(ngrams(*reference, i))\n",
    "    print(\"{}-grams: {}\".format(i,ref_i_grams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculer la précision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "précision de 1-gram = 4/7\n",
      "précision de 2-gram = 1/6\n",
      "précision de 3-gram = 0/5\n",
      "précision de 4-gram = 0/4\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import modified_precision\n",
    "\n",
    "precisions = []\n",
    "for i in range(1,5):\n",
    "    precision = modified_precision(reference, candidate, i)\n",
    "    precisions.append(precision)\n",
    "    print(\"précision de {0}-gram = {1}\".format(i,precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facteur de pénalisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import brevity_penalty\n",
    "\n",
    "ref_len = len(reference)\n",
    "cand_len = len(candidate)\n",
    "BP = brevity_penalty(ref_len, cand_len)\n",
    "print(BP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculer Bleu score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-93a0cd86000f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexp_log_precisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp_k\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mBLEU_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mexp_log_precision\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexp_log_precisions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mBLEU_score\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mexp_log_precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBLEU_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-93a0cd86000f>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(p_k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# exp(log(0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexp_log_precisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp_k\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mBLEU_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexp_log_precision\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexp_log_precisions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "from math import exp, log\n",
    "# exp(log(0))\n",
    "exp_log_precisions = map(lambda p_k:exp(1/4*log(p_k)), precisions)\n",
    "BLEU_score=BP\n",
    "for exp_log_precision in exp_log_precisions:\n",
    "    BLEU_score *= exp_log_precision\n",
    "print(BLEU_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples:\n",
    "#### - 1 phrase 1 référence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# score = sentence_bleu(reference, candidate)\n",
    "## solutions:\n",
    "# 1- préciser le n:\n",
    "# score = sentence_bleu(reference, candidate, weights=(0.5,0.5))\n",
    "# 2- utiliser smoothing functions:\n",
    "# from nltk.translate.bleu_score import SmoothingFunction\n",
    "# my_smoothing_function = SmoothingFunction()\n",
    "# score = sentence_bleu(reference, candidate, smoothing_function=my_smoothing_function.method0)\n",
    "# 3- utiliser emulate_multibleu\n",
    "# score = sentence_bleu(reference, candidate, emulate_multibleu=True)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 1 phrase plusieurs références:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.691441569283882\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "references = [\"my name is hamza jamal how about you?\".split(), \"hamza jamal is my name and you?\".split()]\n",
    "candidate_2 = \"hamza jamal is my name how about you?\".split()\n",
    "score = sentence_bleu(references, candidate_2)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - text (plusieurs phrases) plusieurs références:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
